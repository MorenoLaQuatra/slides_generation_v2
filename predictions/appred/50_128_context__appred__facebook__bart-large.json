{
    "predictions": [
        {
            "id": "11",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\n....\nThis work is based on the work of [Karimireddy et al., 2019, Stich et al. 2018]\nTheorem 1 (strongly convex, smooth).\nWe then use properties of the Count Sketch to extend our theorems to smooth nonconvex and non-smooth convex functions; these are presented as Theorems 4 and 5 in the Appendix B..Theorem 2 (weak convex and smooth convex)\nSketchings\nTheoretically, we can combine the features of the count sketch and the stack of weights.\nWe can combine these features with the stack and weights\nEach worker transmits the gradient instead of the gradient gradient.",
            "result_pred": "Experiments\nWe run experiments on a transformer model, an LSTM, and a residual network, demonstrating up to a 40x reduction in total communication cost with no loss in final model performance\nWe also show that SKETCHED-SGD has favorable convergence rates on several classes of functions\nWhen considering all communication - both of gradients and of updated model weights - SKETChED+SGD reduces the amount of communication required compared to other gradient compression methods\nThe reduction is due to the fact that the communication time overwhelms the local computation time\nThis results in a significant drop in communication cost and degrading model performance.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "13",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nSSTochastic Gradients\nStochastic gradients\nSTOCHASTIC GRADientsStochastics\nSTochastics\nThe use of stochastic gradient Langevin dynamics\nThe application of Stochastic Grads\nWe use Stochastics\nWe apply Stochastsics\nOur approachWe use stochastics.Our approach\nOur method: Stochastically Gradient Langevin Dynamics\nHow do we use Stoclasts?How does our method?\nWhat are Stochasticals\nWhy do we need Stochustrics?\nWhat is Stochasty Gradients?",
            "result_pred": "Evaluation\nWe evaluate SWAG predictions and uncertainty estimates on image classification tasks.\nThe low-rank plus diagonal version of SWAG is generally better calibrated than SWAG-Diagonal.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "17",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nGeneralization bounds\nWe first focus on the training set size.Generalization bound\nTraining set size\nThe training dataset sizeThe training data set size\nThe generalization bound\nTraining dataset size:\nIn this work, we consider the set of parameters parameters, including the size of the training dataset.\nWe also consider the generalization bounds, including different values of m [30].We show that for this particular stopping criterion, the test error empirically decreases with size m as 1/m 0.4 as seen in Figure 1 (third plot). However, we will see that the story is starkly different for the generalized bounds, as shown in Figure 2 (fourth plot).\nOur findings\nOur results\nOverall, we show that, even though distance from initialization would help explain generalization better in terms of width, it conspicuously fails to help explain its dependence on size.<et>We also show that the distance from initialization is width-independent (and even decreases with width); hence, they concluded that incorporating the initialization would improve generalization binding by a \u2126( \u221a h) factor.",
            "result_pred": "Evaluation\nWe see that applying uniform convergence on this set of classifiers will yield only a vacuous generalization guarantee larger than 1\nThis is consistent with previous work on deep learning.\nIn fact, it is more probable than not that uniform convergence can explain generalization.Results on Deep Neural Networks\nResults on deep neural networks\nWe observe that the power of uniform convergence is limited to a small extent.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "20",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nSample Replay Buffer\nSample replay buffer\nLangevin dynamics does not place restrictions on sample initialization.Sample replay Buffer\nWe take two views of the energy function E: firstly, it is an object that defines a probability distribution over data and secondly it defines an implicit generator via (1).\nOur approach\nSamples are generated implicitly \u2020 by a feedforward network.\nWe sample from B 95% of the time and from uniform noise otherwise.<et>We use a sample replay buffer in which we store past generated samplesx and use either these samples or uniform noise to initialize Langevin dynamics procedure.Sample Reinforcement\nOur model is based on a deep neural network parameterized by weights \u03b8.",
            "result_pred": "Evaluation\nEvaluated on CIFAR-10 and ImageNet image datasets.\nEfficiency of generation quality:\nGenerated images are more energy efficient than those generated with explicit generation.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "27",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nWe are the first to make such quantification.We show a dimension independent lower bound on Y t\nOur approach: Stochastic Gradient Descent\nStochastic gradient descent\nWe show that the class of SGD with diminishing stepsizes as a function of only global parameters \u00b5 and L we show a probability density g\u03be t.\nOur results:\nThe results of our approach:The results from our approach\nThe predictions of our method\nScheduled stepsize sequences\nStepsize sequences for each sequence\nAssumption: The sequence of stepsizes of [17] and [7] are optimal in that it leads to minimal expected convergence rates Y t for all sequences: For each stepize sequence we will show the empirical lower bound for all possible stepsize sequenceAssumption and Recurrence\nRecurrence on Yt\nThis recurrence plays a central role in proving our lower bound.",
            "result_pred": "Experiments\nWe study the convergence of Stochastic Gradient Descent (SGD) for strongly convex objective functions\nWe prove for all t a lower bound on the expected convergence rate after the t-th SGD iteration\nThe lower bound is over all possible sequences of diminishing step sizes\nIt implies that recently proposed sequences of step sizes at ICML 2018 and ICML 2019 are universally close to optimal in that the convergence rate before each iteration is within a factor 32 of our lower bound\nThis factor is independent of dimension d",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "32",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "Task\nModular latent factor models\nModularity of latent factors\nModel the latent factors\nModel latent factors with respect to latent factors.Modularity with latent factors:\nLSTM\nThe latent factors of latent variables.\nHow can we use them?\nWhat is the latent factor model?We use latent factors to model the latent variables\nWe apply latent factors in the model\nOur approach\nOur methodOur approach\nThis approach is based on latent factors and latent factors, respectively.\nWe focus on latent features\nIn our approach, we use latent features to model latent features.<et>Our method\nThis method has two steps\nFirst, we add a weak signal-to-noise ratio\nSecond, we remove the latent features from the model.",
            "result_pred": "Experiments Synthetic Data\nStanford Natural Language Processing Toolkit (SNLWP)\nFOUNDATION: Neural Information Processing Systems (Nipat et al., 2017)Results synthetic data\nResults - synthetic data\nCorEx consistently outperforms state-of-the-art estimators at a fraction of the computational cost",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "41",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nHigh-frequency wave-series\nLow-frequency Wave-series\nHigh frequency Wave-Series\nMwF Factor AnalysisHigh-Frequency Wave-Sets\nWe use two layer recurrent architectureWe use a two-layer recurrent architecture.Our approach\nOur approach is based on a two layer architecture.\nWe apply scheduled sampling which can be implemented easily in the online case and has shown better performance than others [22].\nIn our implementation, we use scheduled sampling, at the i th epoch of training, to generate a new policy which is a combination of the previous policy and the actual system behavior [21].Inference\nInference is performed by using equation 1 .\nThe model is trained on the test set to generate the new policy\nThen, it applies the new model on the Test set to create the new Policy\nOur model is tested on the sample sequence of input data with length \u2206k\nResults\nOutline\nResults and Future Work\nTwo layer recurrent network\nTwo layers recurrent network\nDependency on the model\nSensitivity of the model to the model\nDependent on the network modelDependent upon the model model",
            "result_pred": "Experiments\nFDA-and IRB-approved study of a BMI with a 32 year-old tetraplegic (C5-C6)\nWe report root mean square error (RMSE) and R2 as measures of average pointwise error and the strength of the linear association between the predicted and the ground truth signals, respectively.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "57",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nSDP(I)\nLow-rank solutions\nHigh-rank solution\nWe show a contradiction to the fact that X \u21e4 is extreme.We also show that Y \u21e4 violates ith affine constraints by at most \u270fL i .\nOur approach\nWe propose a new approach to low-rank optimization\nIn this section, the algorithm may involve solving an optimization under a matrix linear inequality, which may not give an answer representable in finite bits of computation, but may not be a problem either.\nOur proposalOur approach\nThe algorithm may include an optimization of the matrix linear inequalities\nIt may also involve a reduction of the linear constraints by the constraint X I n .The algorithm could involve a linear optimization under the constraint Y I n\nThis approach may involve the optimization under Gaussian constraints\nMapping the matricesMapping of matrices\nThe matrices may be long vectors\nMatrices may have a fixed length\nThey may not have a finite lengthSDP-DIMENSION-REDUCTION\nDimension-Reduction ApproachDimENSION REDUCTION\nDimmension Reduction Approach<et>Dimmering-reduction algorithm\nReduction algorithm\nReducing algorithmReduction algorithms\nRanking algorithm",
            "result_pred": "Results\nAny extreme point solution to the SDP has rank at most d.\nGiven m datapoints partitioned into k groups, the algorithm runs in O(nm + n 6.5 ) time\nFor each group, there exists a polynomial time algorithm for FAIR-PCA with k groups that returns a d + jq 2k + 1 4 3 2 k -dimensional embedding whose objective value is at least that of the optimal d-dimensional embeddings under the same assumptions as in Theorem 1.1.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "58",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nKernel Machine Committee based Active Learning\nThe KMC objective function is a logistic function, which is non-conjugate to the Gaussian prior p(w|\u03b1), the integration can not be straightforwardly performed.We propose a new approach to the KMC problem\nWe propose an approach that is straightforward to perform:\nOur approach\nThis approach is based on a Bayesian RVM modelOur approach is straightforward:The model can be applied to a variety of problems\nIt can be used to solve a number of different problems.\nThe model is simple to perform\nOne-versing strategy\nWe adopt the one-versable classification problems, and we apply the oneversing strategies, and our approach can be straightforward to be straightforward.",
            "result_pred": "Experiments\nExperiments conducted over both synthetic and real data and comparison with competitive AL methods demonstrate the effectiveness of the proposed model.\nWe first investigate and verify some important model properties by using synthetic data and through comparison with SVM and RVM.Results Data Samples\nResults - Data Samplings\nBy joining a sparse Bayesian model and a maximum margin machine under a unified kernel machine committee (KMC), the proposed AL model is able to identify a small number of data samples that best represent the overall data space while accurately capturing the decision boundaries.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "74",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nCompression Quality\ncompression quality\ncompressed embedding qualityCompression quality\nCompressed embeddings Quality\nQuality of the compressed embedding\nPerformance Quality<et>Compressed and uncompressed performance\nQuality and performance of the uncompressed embedingPerformance Quality & Performance\nPerformance quality & performanceQuality & Performance\nThe performance quality of the compression embedding relative to the compressed embeddedding.The quality of a compressed embedding relative to compressed embedDings.\nThe compression quality of an uncompressed word embedding:\nWhat about the performance quality?\nHow do we measure the quality of compressed embedds?\nHow can we measure it?What about compression quality?<et>The performance performance of compression quality",
            "result_pred": "Empirically, we observe that compressed embeddings with large values of \u22061 and \u22062 can still attain strong generalization performance.\nE.g., the logistic loss function can still out-perform the one using a closed-form expression\nLogistic loss is still the largest drop in performance, even though it has been partially mitigated by compression.Results\nResults for the squared loss are similar to those for random label vectors.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "75",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nWe propose a probabilistic graphical model, inspired by Kim and Ghahramani (2012).\nWe develop a generative model, illustrated in Figure 1, of the transfer models' predictions, y ij , yij , and yj .\nThe model is trained on a corpus of transfer models, yiJ , yj, and yi.The model's predictions are based on the model's own predictions, ij, xi, and xj.\nThe transfer models are trained on different models, iJ, xj, yj\nOur approach is to select a subset of component models carefully, or more generally, as we show in \u00a74, where we show that the model performs better in a cross-lingual transfer setting, i.e., yi and xi .We show that model performance improves with the number of models trained on the corpus\nModel performance is improved with the size of the models\nTransfer models have identical predictions, k, on an instance,Model performance and model performance\nModels have similar predictions, x, y, and z\nMapping the model to the corpus\nModeling the model with the corpus of model transfer modelsModeling model performance with the datasetMapping model performance to the dataset\nModel perform better with the data\nLinguistic differences between models<et>Model perform worse with dataTransfer models perform worse\nImportance of label labels\nTransition models have different predictions\nTasks\nHow might we proceed to learn the relative quality of models in the setting where no annotations are available in the target language?\nIdentifying model performance in the context of the model transfer model\nTraining model performance\nTrain model performance on the target modelTransition model performance: transfer models perform better\nIn practice, the model perform better than the model in the source language\nThis is true for all models, but not all models have the same predictions.",
            "result_pred": "Results Direct Transfer\nResults - Direct Transfer\nMv tok with uniform expertise and no fine-tuning\nAn unsupervised transfer model with uniform expert and uniform expertise\nA.g. id vs. ar\n(a) Named Entity Recognition\n(b) NamedEntity RecognitionResults Low Resource\nDirect Transfer Results - Low Resource",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "78",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nGender DiscriminationGender Discrimination\nGrammatical Gender Discrimination\nMorphological Gender Discrimination<et>Morpho-syntactic gender discrimination\nSensitivity to gender differences\nGender Differences\nThe number of grammatical genders varies between different languages, with two being the most common non-zero number.The gender disparity between male engineers and female engineers\nFemale engineers are more likely to be male engineers than male engineers are.\nThe amount of gender differences between female engineers and male engineers is greater than that of male engineersFemale engineers tend to be female engineers.",
            "result_pred": "Intrinsic Evaluation\nWe focus on whether our approach yields the correct morphosyntactic tags and the correct reinflections for gender.\nFor each annotated sentence, we intervened on the gender of the animate noun.Results\nGender stereotyping (left) and grammaticality (right) using the original corpus, the corpus using na\u00efve swapping of gendered words, and the corpus following CDA using our approach.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "79",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "Task-Image Relationships\nTask: Image+Text Task\nImage+Text task\nImage +Text task\nText-Image relationships<et>Text-image relationshipsImage-image relationships\nText and image pairs\nThe image task and image pairThe text task and the image pair\nThe text-image pair\nWe define and annotate using the following guidelines: Combining the labels of the two binary tasks described above gives rise to four types of semantic relationships (image+text task).\nAll of the four relationship types are exemplified in Figure 1.\nGender was considered binary 2 and coded with Female -1 and Male -0.Gender and gender pairings are represented as ordinal variables\nAge is represented as a integer value\nWomen and gender pairs are represented by an ordinal variable\nFemale -1 is represented by a binary variable\nFemale-1 and male -0 are represented with a binary valueWe define the relationship between the text and image in the same social media post, we define a new annotation schema and collect a new annotated corpus.\nWe use Twitter as the source of the text, and annotated the corpus with the same annotation schema\nAnnotation schema\nAnnotated corpus\nIn this paper, we focus on image-image pairsAnnotation schemaText and text pairings\nLanguage and text pairs\nLanguage & text pairs are distinguished by the image pairs.",
            "result_pred": "Experiments\nText in social media posts is frequently accompanied by images in order to provide content, supply context, or to express feelings\nSocial media posts are often accompanied by text in order: to provide context, to express sentiment, or both.\nThe meaning of a tweet is essentially the same as that of a Facebook post, but the meaning is altered by user data.Results\nResults of a Twitter experiment\nTwitter experiment conducted on 1k tweets using hashtags.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "80",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "We aim to perform our analysis on a set of users from the same domain to limit variations caused by topic and we observe that the most numerous category of users who sign their messages are U.S. politicians, which leaves us with 147 accounts.\nWe remove the retweets made by an account, as these are not attributed to either the account owner or their staff.\nWe manually identified each user's signature from their profile description.We use a broad set of linguistic features motivated by past research, including some specific parts-of-speech, topical or stylistic categories.",
            "result_pred": "Experiments\nWe analyse the linguistic topics and style features that distinguish the two types of tweets\nWe also study the linguistic differences between posts signed by the account owner or attributed to their staff\nFor each tweet, we find that the author of the tweet has at least one of the following linguistic features:\nThe author of a tweet uses a signature to distinguish his or her tweetsResults\nResults are statistically significant compared to previous work.\nPredictive results show that we are able distinguish between owner and staff attributed tweets with good accuracy, even when not using any training data.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "85",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ". refer..... refer.\n\n.... refer to the saliency of the prediction score...\nModel Prediction\nModel prediction score\nModeling saliency\nModelling saliency\nTraining saliency with the model\nSaliency prediction score\nSalient prediction score:\nThe saliency score is computed before prediction of t j or t \u2032 j .Salient predictions with the input feature\nSensitivity of the feature to the model\nThe feature weight is computed prior to prediction of T j or T \u2032 J .\nWe argue that an ideal interpretation algorithm should be able to adapt the interpretation with the specified output label, regard-less of whether it is the most likely label predicted by the model.\nWe propose that the model should predict saliency based on the feature weight, with respect to the prediction of the input features\nThis is essentially re-formulating the perturbed prediction score p(y 0 | x) as a partial derivative of the salient score.We also propose that we can use the model to predict salient scores for each feature, with regard to the feature weights.<et>We show that this is not possible with the attention weight interpretation, since the attention weights are computed before predictions of tj or tj .\nOur approach\nWord Density\nWord densityWord ddensity\nDensity\nword density\ndensity refer to word densityword density\nworddensityWord density<et>Word densitySemantics\nWhat is saliency?\nHow does saliency affect a prediction score?Sensitivity to saliency is determined by saliency scores\n(x 0 ) is an input feature and x 0 is an output featureWe propose a new approach for saliency prediction.",
            "result_pred": "Evaluation Method\nEvaluations of interpretations is tricky!\nFortunately, there's human judgments to rely on.\nNeed to do force decoding with NMT model.Human Evaluation\nHuman Evaluation:\nTake the NMT prediction, obtain reasonably clean reference alignments between the prediction and the source\nMeasure AER against the human alignment\nSaliency-driven Word Alignment Interpretation for NMT",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "93",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nWe propose a task: given a sentence with a target entity mention, predict free-form noun phrases that describe appropriate types for the role the target entity plays in the sentence.Our task effectively subsumes existing finegrained named entity typing formulations due to the use of a very large type vocabulary and the fact that we predict types for all noun phrases, including named entities, nominals, and adjectives\nOur task is much more diverse and fine grained, compared to existing datasets.\nWe also propose a new dataset of 6,000 examples.<et>We propose an approach to the task: Given a sentence, we predict the type of \"chairman\"\nThis approach is not possible given current typing models that only predict relatively coarse types and consider named entities only.Our approach: We propose a model that only predicts relatively coarse-grained entity typing datasets\nThe model is heavily skewed toward coarsegrained type types.",
            "result_pred": "Experiments\n2K crowdsourced data (2K types)\n2.7M entity linking data\n20M head words\nCrowd data: 2,000 examples\nPerformance breakdown for different type granularity and different supervision.\nPerformances by different supervision sources.Evaluation\nPerforms by different supervised types.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "104",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nModel Uncertainness\nWe describe metrics for capturing uncertainty below: Dropout Perturbation\nWe use dropout (Srivastava et al., 2014) as approximate Bayesian inference to estimate model uncertainty.Dropout is a widely used regularization technique during training, which relieves overfitting by randomly masking the input neurons (Gal and Ghahramani, 2016).\nThe model is trained on a Bernoulli distribution (Luong et al, 2015a) to utilize relevant encoder-side context.\nThe training objective is to maximize the likelihood of the generated meaning representation a given input q, i.e., maximize (q,a)\u2208D log p\nDropout: a dropout layer in the decoder\nIn practice, the model is used to initialize the hidden states of the first time step in the Decoder.",
            "result_pred": "Experiments Datasets\nDatasets used in our experiments:\nIFTTT and DJANGO datasets.\nTable 1: Dataset statistics for IFTTT (Table 2: Data Statistics for DJANgo (Table 3)Results\nTable 4: F1 vs confidence metrics.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "127",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "Semantics\nThe question is: What is the answer?\nWhat is the right answer?\nWhat are the right answers?The question: What are the correct answers?<et>The answer is: what is the correct answer?The answer: which is the appropriate response?.\nHow do we choose the right response?",
            "result_pred": "Evaluation Methodology\nWe follow the existing work and employ both automatic and human evaluations.\nWe see the following observations:\nThe max inverse word frequency in a response is a good distant label for the response specificity.Human Evaluation\nHuman Evaluation: 3 labelers with rich Weibo experience were recruited.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "135",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nWord embedding\nThe word embedding framework\nThe metaphor identification framework is built upon the Continuous Bag of Words (CBOW) and Skip-gram (Mikolov et al., 2017).\nWe use the same model as CBOW.The model is based on the theory of Selectional Preference Violation\nIt is a hypothesis that a metaphorical word can be identified, if the sense the word takes within its context and its literal sense come from different domains.\nOur framework is based upon the same hypothesis.",
            "result_pred": "Experiments\nMetaphoric expressions are widespread in natural language, posing a significant challenge for various natural language processing tasks\n(1) Metaphorical expressions are universal in nature, and (2) they can be used to express a variety of phenomena.\nMeta-identification is tricky!\nFortunately, there's human judgments to rely on.Results\nResults for English to Chinese\nTwo systems outperform strong baselines.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "151",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\n....\nHow can we combine as-graphs with each other using two linguistically motivated operations: apply and modify a modifier?\nApplying and modifying a modifier\nModifying a modifier\nApplied and modifying an adverb modifierModifier\nAdverb modifier<et>Adverb modifiers\nModifier\nA-source and an O-source\nAnnotation of the a-source\nAnnotations of the an-source & an-O-source.\nThe annotations, written in square brackets, are the same as the annotations, but they are not the same type of graph.",
            "result_pred": "Results\nOn the 2015 dataset, our best models (local + projective) outperform all previous work, with the exception of the Foland and Martin (2017) model.\nThe fact that our models outperform the JAMR-style baseline so clearly is an indication that they indeed gain some of their accuracy from the type information in the elementary as-graphs, confirming our hypothesis that an explicit model of the compositional structure of AMR can help the parser learn an accurate model\nType-unaware baseline has low recall, due to its inability to produce well-typed trees.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "179",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nWe build a framework to represent each AMR relation, composing its semantics with two concepts for each tuple (in Section 4), and feed all tuple representations into a CNN to generate a dense vector representation V St for the event mention structure.We use the same word sense disambiguation (WSD) tool (Zhong and Ng, 2010) to identify candidate arguments and apply the same WSD tool to candidate arguments\nWSD and candidate arguments\nWe use WSD as candidate event triggers, and identify candidate argument role\nThe candidate arguments based on AMR and WSD\nOur framework is based on an AMR framework, and the candidate arguments are based on WSD.\nThe framework is built using AMR & WSD, and we identify candidate event trigger, candidate argument, and candidate argument roles\nIn order to incorporate the contexts into the semantic representation of t, we build a structure S t as shown in Figure 3\nThis structure is a matrix to represent the AMR relations, and it is used to capture the context of each tuple.",
            "result_pred": "Experiments\nExperiments conducted on 23 unseen event types\nWe select, for each event mention, the event type which is semantically closest in this space as its type\nBy leveraging manual annotations available for a small set of existing event types, our framework can be applied to new unseen types without additional manual annotations\nWith manual annotations, our zeroshot framework achieves performance comparable to a supervised model trained from 3,000 sentences annotated with 500 event mentions\nManual annotations are still the most widely used annotation for event extraction.\nIn Proceedings of the 9th Joint Conference on Neural Information Processing Systems, ICAC '12.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "183",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nWe choose GRUs instead of LSTMs because we first used bidirectional GRUs, which are able to capture the contextual information between words.We chose GRUs for the text attention module\nThe model consists of three major parts:\nAudio attention module\nThe audio attention module extract the features from embedded text input at the word level\nText attention module apply the features to the audio input\nAttention distribution model\nWordlevel attention strategy\nWord level attention strategy\nFlexible wordlevel attention modelAttention Distribution Model\nIn this work, we first use the word2vec (Mikolov et al., 2013), which gives us the best result compared to GloVe and LexVec.\nWe then apply the word-level attention module to the text input, using the same approach as we used for the audio attention model.",
            "result_pred": "Experiments Datasets\nExperiments: Dataset (Datasets)\nHuman Attribute Detection\nHuman Affect Detection\nTrain: sing-song utterance level sentiment and emotion from text and audio data\nTest: word-level fusion\nFusion strategies only fuse different modalities at abstract levels, ignoring time-dependent interactions between modalities\nSynchronized attention over modalities offers visual interpretability.\nMultimodal affective computing, learning to recognize and interpret human affect and subjective information from multiple data sources, is still challenging because: (i) it is hard to extract informative features to represent human affects from heterogeneous inputs\n(ii) current fusion strategies are prone to degenerate performance due to the limited number of modalities.Experimental Results\nOur model outperforms state-of-the-art approaches on published datasets.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "232",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nQuestion-based answer tokens\nWe explore two approaches to extract answer tokens: \u2022 Entities.We extract four types of named entities {PER, LOC, ORG, MISC} from sentences and treat them as possible answer tokens.\nWe use a questionoriented reward vector\nA context vector c k is a weighted sum of all summary words relevant to the k-th question, and it is used to predict the answer.<et>Question-Based Answer Tokens\nThe answer token is replaced with a placeholder, yielding a Cloze question\nThis approach identifies the ROOT word of a sentence dependency parse tree and treats it a keyword-based question token, then convert the sentence to a question by replacing the token with a statement of the answer token.",
            "result_pred": "Experiments\nCNN dataset [Hermann et al., 2015]\nTrain/valid accuracy and R-2 F-scores when using varying numbers of QA pairs in the reward function.\nWhen using entities as answers, the training accuracy is 34.8% and 21.9% for Q5, suggesting that using sentence root words as answers is a more viable strategy than using keywords as answers.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "241",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "\nKeyphrase Extraction\nKeyphrNN Encoder-Decoder ModelKeyphrase Keyphrases\nThe keyphrase provides a succinct and accurate way of describing a subject or a subtopic.\nA number of extraction algorithms are widely employed in the process of extracting keyphrasing\nThe top-ranked candidates are returned as keyphrase in the given document.The top ranked candidates are given a keyphrase in the document\nThis model was trained with the title-summary, and may diverge from the real objective generating keyphRases.<et>The model is trained with a title summary, and is unable to handle semantic meaning.\nIt was first introduced by  and and Sutskever et al. in 2013.",
            "result_pred": "Evaluation Metrics\nMicro-averaged precision, recall and F-measure (F1) are employed for measuring the algorithm's performance.\nProceedings of the 9th International Conference on Autonomic Computing, ICAC, Vancouver, Canada, 2019\nKeyphrase provides highly-summative information that can be effectively used for understanding, organizing and retrieving text content.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "247",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nWord-to-word coverage\nWord to word coverage\nVocabulary distribution\nThe attention distribution can be viewed as  For each decoder timestep a generation probability p gen \u2208 [0, 1] is calculated, which weights the probability of generating words from the vocabulary, versus copying words from a fixed vocabulary.Vocab-based coverage model\nThe vocabulary distribution and the attention distribution are weighted and summed to obtain the final distribution, from which we make our prediction.\nWe use a single-layer bidirectionality model (Vinyals et al., 2015), as it allows both copying words via pointing, and generating word from the source text.",
            "result_pred": "Experiments\nWe train using Adagrad (Duchi et al., 2011) with learning rate 0.5.\nThe pointer-generator model makes much quicker progress in terms of training\nIn the first few iterations, the coverage loss converged to about 0.2, down from an initial value of about 3.7.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "269",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nPhrase-Based Translation\nThe Syntactic Language Model\nThe syntactic language model probability of a partial sentence e 1 ...e t is defined: \u03c4 \u2208\u03c4t P(e1 ...e2 ...e3 ...e4 ...e5 ...e6 ...e7 ...e8 ...e9 ...e10 ...e11 ...e12 ...e13 ...e14 ...e15 ...e16 ...e17 ...e18 ...e19 ...e20 ...e21 ...e22 ...e23 ...e24 ...e25 ...e26 ...e27 ...e28 ...e29 ...e30 ...e31 ...e32 ...e33 ...e34 ...e36 ...e37 ...e38 ...e39 ...e44 ...e46 ...e47 ...e48 ...e55 ...e56 ...e57 ...e58 ...e59 ...e61 ...e62 ...e63 ...e64 ...e65 ...e66 ...e67 ...e68 ...e72 ...e73 ...e74 ...e76 ...e77 ...e78 ...e79 ...e80 ...e81 ...e82 ...e84 ...e85 ...e86 ...e87 ...e88 ...e89 ...e92 ...e93 ...e94 ...e96 ...e103\nIncorporating a Phrase-based Translation ModelPhrase Based Translation Models\nAn incremental syntactic model is used to process sentences in an incremental left-to-right fashion, generating words at the beginning of a translation first and words at each node in the translation lattice.\n...lam refer Monteneg\n refer refer to the model as a model\n refer to it as a language model.Refer to it by the model model as the model of a model model model.\nUse the model to process the tth token in string e, an incremental parser has some internal representation of possible hypothesized hypotheses\nSelecting a Syntactic language representation\nSelect a syntax language representation\nIdentifying a syntax-based translation model<et>\nIdentify a syntax model to parse the target language words\nChoose a syntax for each target language wordIdentify the syntax for every target language sentence\n",
            "result_pred": "Experiments\nWe trained a phrase-based translation model on the full NIST Open MT08 Urdu-English data, using the full training data.\nMoses was first configured to use just the n-gram LM\nThe syntactic LM feature was then further tweaked to use both the n -gram LM and the syntactic HHMM LMEmpirical results\nMERT consistently assigned positive weight to the syntax LM feature\nFigure: Effect of constrained devtest set on BLEU and Per-word perplexity\nBLEU is the most commonly used measure in EMNLP.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "277",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "Semantics\nCross-Language Alignment-based Similarity Analysis\nSimilarity Analysis\nComparison and Similarity (CL-CnG)\nClustering of parallel and comparable corpora\nComparative and similar corpora\nConclusions\nWe propose a cross-language similarity detection model that captures both parallel and similar corpus.\nOur approach is based on the same approach using DBNary.Our approach: Cross-Language Similarity Detection\nThe dataset is specially designed to measure the semantic similarity using abstract con-cepts from words in textual units.\nWe use the same dataset as before, but we augment the state-of-the-art methods to verify the complementarity of the corpusWe use a similar approach using the same methods as before\nIn our implementation, these concepts are given by a linked lexical resource called S\u00e9rasset, followed by product reviews, product reviews and product reviews\nDBNary (S\u00e9raset, 2015).\nS\u00e9rassets are used as word embeddings\nThey are also used as vector representations.<et>We propose cross-Language alignment information at different granularities: document level, sentence level and chunk level; \u2022 it is based upon both parallel-language alignment information\nThis approach: Similarity Alignment - Based Similarity\nOur implementation: Similarities Alignment\nSimilarities across corpus\nDifferent types of corpus\nDifferent kinds of corpus",
            "result_pred": "Evaluation\nCl-WES obtains overall performance gain of +3.15% for English-French similarity detection at chunk level and +14.5% at sentence level\nDespite this improvement, CL-CTS-WE remains less efficient than CL-C3G\nThe F 1 score is the harmonic mean of precision and recall.\nRecall is the proportion of relevant matches retrieved among all the relevant matches to retrieve.Results\nResults of the decision tree fusion are reported at both chunk and sentence levels.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "316",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "Task-based Parser\nTask based Parser\nTransition-based parserTask based parser\nThe parser needs to predict the next action based on its current state.The stack stores words, the buffer of the stack stores the stack, and the output of the buffer contains the stack.\nA stack of words is stored in the stack\nWords in the buffer are processed left-toright until an end state is reached, at which point the set of arcs will contain the full output tree.\nThe stack holds words and the buffer stores words.",
            "result_pred": "Experiments\nWe first run experiments on single-task semantic parsing to observe the differences among the three different data sources.\nOvernight data set (Overnight)\nNLmaps data (NLmaps)Experiment Data Statistics\nExperiment: Data Statistics\nWe study the impact of an attention mechanism on performance as well as the comparison between delexicalization and a copy mechanism for dealing with data sparsity.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "317",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nShort-title generation of news articlesShort-Title Generation\nWe report on a case study of short-title Generation of news article for a real-world application of neural headline generation.We focus on two approaches:\nThe first approach is to merge all sources with some weights based on the importance of each source, which can be achieved by a weighted average of the context vectors, and the third approach can be reduced to the normal encoder-decoder model.\nThe second approach is a conditional language model, which has been extensively studied, as described in Section 6.<et>The third approach is the weighted average approach and compared our proposed model to the first approach.",
            "result_pred": "Crowdsourcing tasks\n10 workers were asked to score each generated short title on a four-point scale (higher is better)\nThe score of each generated Short Title was calculated by averaging the scores collected from the editors before and after the release of HybridFusion.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "331",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".. . . .\n. .. ..\nHow do we check the validity of the first person?\nThe first person appearance is of 1.21% in a Basque objective corpus (Basque Wikipedia) whereas its appearance in the literature is of 8.37% in the Basque Opinion Corpus\nEach person annotated in 20 minutes while movie and literature texts were annotated by one hour.The time to annotate documents varied from annotated documents varied, consequently, the corpus is useful for sentiment analysis.\nThe amount of annotated texts varied from corpus to corpus\nIn order to check the quality of the annotation process, inter-annotator agreement was measured.<et>Inter-annotators have to train more to reach a higher agreement.",
            "result_pred": "Experiments Basque Opinion Corpus\nExperiments: Baske Opinion Corpus\nWe have extracted the subjectivity of several rhetorical relations and the results show the effect of sentiment words in relations\nFor all relations, sentiment is the most important measure.\nToward a better understanding of the text structure, we have tried using Rhetorical Structure Theory (RST).\nThe results are asymptotic as they are disordered.Evaluation Basques\nBasques ranked according to sentiment and coherence relations",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "332",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nDiscourse Structure\nDiscrete Structure\nConclusions and Future Work\nThe use of deep hierarchical discourse structures to evaluate text coherence.Discrete structure\nDeconstructing discourse structureConclusions & Future work\nWe propose a new approach to the analysis of the discourse organization of written texts\nOur approach is the automated evaluation of discourse in student essays, i.e., the automated assessment of discourse coherence in a student essay\nThis approach is based on deep discourse structures and is the same as that used in the previous work (Wang et al., 2013) and demonstrated the positive impact of using deep discourse structure to evaluate speech coherence .\nIn this work, we focus on the use of discourse relations in a corpus of non-native spontaneous speech in which each response was assigned a coherence score on a scale of 1 to 3, and several surface-based features were used to count the responses.",
            "result_pred": "Experimental Setup\n12,194 speakers (73,164 responses) were used as the training set\n5,000 speakers (30,000 responses) to test the model performance\nSpear-to-Spear Conversations (Spear2Spear)\nEight discourse features extracted from automatically parsed RST treesResults\nResults of the first experiment with SpeechRater features can reach an accuracy of 65.9% on an independent evaluation set with non-native discourse features\nImprovement is limited due to the limited number of discourse features that can be used to assess the discourse structure.\nHuman evaluation results are not available for this large data set.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "337",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nN-grams\nWe tested various maximum n-gram lengths, and we found that the models performed the best.We tested several different kernels, we tested several types of kernels\nThe kernels that performed the most were the linear, sigmoid, and radial basis function\nPolynomial kernels, subst-count string kernel based on a string kernel\nSigmoid kernels and subst-out kernelsSigmoids & subst-of-string kernels\nWe found that these kernels perform the best, but training the models specifically for the same task, they achieved 99.7% accuracy\nIn our initial experiments, we used the linear kernel to perform the task, but we found the kernels performed the better, but they performed the 50 average score of a score, and they achieved a 50 average scores of a pair of kernels,Ngramgrams\nNgrams & strings\nLanguage SVMs\nSVMs and stringsLanguage SVM and strings\nLanguage VMs\nVMs: SVMsVMs & strings<et>SVM & strings: SVM\nVariable N-gram length\nLinguistic features\nVariable word lengthVariable Ngram length\nVm and strings: Vm\nDramatic features\nNumber of words",
            "result_pred": "Experiments\nTransfermarkt corpus of soccer player names\nCEJ corpus of Chinese-English-Japanese (CEJ) first names and surnames\n1. Name identification over the whole set\n2. Language identification over 1000 tagged names using the parameters from above.\n3. Transliteration model with n-gram counts performs much better than language models using only character-level language features\n4. Transliteration model trained over the full data does not compete with existing state-of-the-art language models\n5. Language model with character level language features performs better than models using character level only features",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "340",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "Prepositional Polysemy\nThe Preposition Project (TPP; Litkowski and Hargraves, 2005) broke ground in stimulating computational work on fine-grained word sense disambiguation of English prepositions.\nPreposition Project\nThe preposition project (TPP); Litkowski et al., 2005.Preposition and Supersemy\nSupersemy and Superposition\nSuperpositional and Prepositional UsageSuperposition and Preposition Usage\nSupersenses\nSuppositional Prepositions\nPropositional & Superposition Usage\nProposition & Superpositional Use\nSets of prepositional words\nSubpositions and Superpositions\nSubposition & Suppositional useSets and Suppositions:\nWhat is a supersense?\nA supersense is a set of preposition-marked relations between entities.\nA preposition is a series of relations between an entity and another entity\nEach preposition has its own set of relations\nThis is not the same as a supersemy.<et>Prepositions & Superposes\nThese are not identical.",
            "result_pred": "Experiments\nExperiments conducted using a broad-coverage annotation scheme\nWe studied the effect of construal in adposition use, expressing such phenomena directly at the token level to manage complexity and avoid sense proliferation.\nThe results are asymptotic as they are disambiguate\nAdposition expressions are temporally and semantically close to their lexical counterparts.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "355",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".. . . .\n. .. ..\nHow do we check the validity of the first person?\nThe first person appearance is of 1.21% in a Basque objective corpus (Basque Wikipedia) whereas its appearance in the literature is of 8.37% in the Basque Opinion Corpus\nEach person annotated in 20 minutes while movie and literature texts were annotated by one hour.The time to annotate documents varied from annotated documents varied, consequently, the corpus is useful for sentiment analysis.\nThe amount of annotated texts varied from corpus to corpus\nIn order to check the quality of the annotation process, inter-annotator agreement was measured.<et>Inter-annotators have to train more to reach a higher agreement.",
            "result_pred": "Experiments Basque Opinion Corpus\nExperiments: Baske Opinion Corpus\nWe have extracted the subjectivity of several rhetorical relations and the results show the effect of sentiment words in relations\nFor all relations, sentiment is the most important measure.\nToward a better understanding of the text structure, we have tried using Rhetorical Structure Theory (RST).\nThe results are asymptotic as they are disordered.Evaluation Basques\nBasques ranked according to sentiment and coherence relations",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "370",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nCross-Language Conceptual Thesaurus-based Similarity (CL-CTS)\nThe model was specially designed to measure the semantic similarity using abstract concepts from words in textual units.The model is based on Mcnamee and Mayfield (2004) model.\nThe dataset is a corpus of Spanish texts from a parallel corpus.<et>The dataset was a dataset of French texts from the same corpus\nWe use the corpus as the basis for our model\nOur model is a model of cross-language similarity detectionOur model was specifically designed to perform a rigorous evaluation of crosslanguage textual similarity.",
            "result_pred": "Evaluation Datasets\nDatasets available at: https://bitbucket.org/datasets/\nCross-lingual similarity detection on a new open dataset:\n6 language pairs on 2 granularities of text units\n10 folds are carried out by changing the M selected units.\nPrecision is defined as the proportion of relevant matches (similar crosslanguage units) retrieved among all the matches retrieved.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "391",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "\nMorphological Type Classification\nWe apply the pattern matching rules described in Table 1 to build a rule-based classifier.\nWe use a corpus-based approach to predict their morphological types.We use corpus-level features to predict the morphological type of their words.<et>We apply corpus-layer features for each word to predict its morphological typology.\nThe three types of baselines are compared:  (Chang et al., 2009)\nDerived Word: Rule-Based Approach<et>Derived word: Rule Based Approach\nThe word-level feature for C 1 C 2\nA single word for C 2 .\nIn this paper, we apply the rule based approach\nOur approach: Derived Word\nOur method: Derive Word\nThis work is based on the literature, and we respectively adopt rulebased and machine learning approaches to predict them morphological Types\nCompound Word Machine Learning\nCompounding Word: Machine Learning\nDedicated Words\nDEDITED WordsDedived Words<et>DEDIVED WORDSThe term \"compound word\" is used to refer to words formed of constituent characters following syntactic relations, such as \"x\" and \"y\".\n\"X\" is the first word formed, and \"Y\" is one of the constituent characters\n(X) is the second word formed\"X-H\" is a compound word, and X-H is the third word formed.",
            "result_pred": "Experiments\nWe performed 10-fold cross-validation experiments on the entire dataset\nRandom Forest and SVM outperformed all other models and baselines\nHuman performance on the \"easy\" instances (human annotators)\nThe best accuracy is 0.674; 65% of words in the initial set are labeled as \"easy\", suggesting that our classifiers are comparable to human performance\nWe achieved similar level of performance in macro F1-measure when compared to Huang et al. (2010) 6 , despite our task being more challenging due to having two extra types.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "405",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "Task\nQuery Performance Prediction (QPP)\nQPP Approach\nQuestion Performance Prediction\nQuery performance Prediction<et>Query performance prediction\nQuestion performance prediction\nThe query performance prediction approach\nThe search system would return in response to a particular query.The query is the query, the channel, and the set of query terms.\nIt is defined as the KL divergence between a language model induced from the result list and that induced from a corpus.\nWe focus on the candidates from a key-list of terms whose coherence in the language is already known.\nWe also focus on candidate terms in the target corpus, the candidate terms, and their coherence with the corpus\nOur ApproachWe use query performance predictions to estimate the quality of answers that a search system will return\nThis approach takes advantage of a typical language model, the corpus, and its coherenceOur Approach<et>Our approach is based on the same approach as the previous work\nIn this work, we focus on a typical linguistic model and the corpus.<et>We also use the corpus as a communication channel.",
            "result_pred": "Evaluation Setting\nThe Responsa corpus comprises of 81,993 documents, and was used for previous NLP and IR research (Choueka et al., 1971)\nIt comprises of rabbinic case-law rulings which represent the historical-sociological milieu of real-life situations, collected over more than a thousand years, from the 11 th century until today.\nThe proposed method further expands modern candidate terms with ancient related terms\nFor example, the Hebrew target term for slippers was expanded by the ancient expression corresponding to made of leather\nThis is a useful expansion since in the ancient documents slippers are discussed in the context of fasts, as in two of the Jewish fasts wearing leather shoes is forbidden and people wear cloth-made slippers.Results\nWhen the QPP score is measured over the expanded candidate and ancient documents are utilized, the performance increase is more notable (5 points) and the improvement over the baseline is statistically significant according to the McNemar's test with p<0.05.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "408",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".com\nWord-News\nWordNews Categories\nNews Categories\nNews-NewsWordNews\nThe learner has encountered the target word a number of times, and the client reveals the correct answer.\nWhen the learner hovers over the replaced word, the test is shown.We use a multiple choice question (MCQ) test to assess mastery.\nWe use the same test to test mastery.We apply the same tests to the new word\nOur approach\nOur method is inspired by earlier work in the computer-aided language learning community\nWe focus on the web browser, and our approach is similar to earlier work on the language browser.",
            "result_pred": "Human subject evaluation\nWe conducted a human subject evaluation of distractor generation to assess its fitness for use.\nThe subjects were asked to rank the feasibility of a distractor (inclusive of the actual answer) by plausibility: 1 (the original answer) to 7 (least plausible alternative)\nA lower rating means a more plausible (harder) distractor.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "419",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "Task evaluation\nThe hypothesis sentence precision score for the reference is 70.75.\nA BLEU score can range from 0 to 1 and the closer to 1 that a hypothesis translation is closer to the reference translation 2 .\nBLEU scores have showed high correlation with human judgements and is still used as the de facto standard automatic evaluation metric for major machine translation shared tasks.The hypothesis sentences are not always matched by the human evaluators\nIn this respect, one would consider the baseline translation inferior to the hypothesis with a >10 BLEA difference.",
            "result_pred": "SegmentLevel Meta-Evaluation\nSegment level meta-evaluation by calculating the BLEU and RIBES score difference for each hypothesis-baseline translation\nHuman evaluators were randomly assigned documents from the test set.\nBLEU and RBES were significantly better than the baseline translation generated by the baseline phrase-based MT system.Human Evaluation\nHuman Evaluation - human evaluationResults\nResults of the WAT 2015 shared task are statistically significant compared to the organizers' baseline.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "424",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nBaseline Systems\nWe used the following baseline system and translation results for each participant's system.Baseline System and Test Results\nThe baseline system was the standard of human evaluation.\nThe test results for the baseline system were the standard for human evaluation\nOur baseline system:\nA phrase-based statistical machine translation (SMT) system was adopted as the specific 2 http://opac.jp/bunrui/index.jst.html\nIn addition to the results for baseline phrasebased SMT system, we produced results for a baseline systems that consisted of hierarchical phrase-to-tree syntaxbasedSMT systemWe used a pairwise comparisons between the translation results and the specific baseline system.<et>We use the following benchmark system and test results\nMoses' configuration for the benchmark system\nSynthesis-based Phrase-to Tree Synthesis\nPhrase-based Synthesis-To-Tree Synthesis & Tree Synthesizers\nSystem description of the baseline SMT systemsSystem description: The baseline system, a string-to tree syntaxbased system, and the target language sentence pairs.",
            "result_pred": "Automatic Evaluation Results\nBLEU and RIBES (Isozaki et al., 2010)\nWe calculated automatic evaluation scores based on two popular metrics: BLEU (Papineni & al., 2002)Official automatic evaluation results\nOfficial automated evaluation results\nJoint evaluation of JE, EJ and HUMAN\nHuman evaluation:\nThe input sentence and two translations (the baseline and a submission) are shown to the workers\nThey are asked to judge which translation is better than the other, or they are of the same quality.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "425",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "Task\nTokenization and Preprocessing\ntokenization and preprocessingTokenization & Preprocessing\nWe use the Stanford Parser (Klein and Manning, 2003), the KyTea toolkit (Neubig et al., 2011), and the Stanford Segmenter (Tseng et al. 2013).\nThe stack of lexical and semantic data is large.We use a number of ways to incorporate these dictionaries, but in the submitted system, we simply added a rule to the translation table for all unknown words that existed in the dictionary.\nThis word appeared prolifically in the dev set (as well as devtest and test), but not once in the training corpus.\nWe also performed case normalization for English, by changing the first word in English sentences to its most common capitalization before training models and translation models\nIn order to solve this problem, we normalized \"\u6a19\u984c\" into the lexically different but semantically largely equivalent \"\u8868\u980c\" (which appeared many times in the translation corpus).Syntactic Parsing\nSyntact Parsing\nSparse trees\nParsing treesSparse tree edges\nSparse tree edges\nTrees are used as trees in the model\nTree edges are used for the model to parse trees\nThe model is used as a tree in the systemThe model uses tree edges as trees for the modelsOur approach\nOur approach is to use tree edges for the parser\nUsing tree edges, the model has an accurate word-by-word representation of the sentence\nUse tree edges to represent the sentence as trees, not as trees.",
            "result_pred": "Official results\nOfficial results for each system:\nBLEU-tuned systems tend to largely match the length of the reference hypotheses, while the systems tuned for BLEU+RIBES tend to result in significantly shorter translation outputs\nHuman evaluation is more important than RNNLM in terms of short- and long-range evaluation.Official Results\nThe official results for the WAT task are asymptotically as good as those in previous work.\nThe F2S translation significantly outperforms PBMT.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "432",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nThe Z-MERT implementation (Zaidan, 2009) of minimum error rate training (Och, 2003) was used for parameter tuning.The WMT-Lopez implementation (Schwartz and Callison-Burch, 2010).\nWMT -Lopez, 2008\nWe use the WMT to train language modelsWe use WMT for training language models.\nWe train language model\nOur approach\nMapping the translation grammars\nSynchronous context free translation grammar is extracted for a particular test set, following the methods of Lopez (2008) as implemented in WMT\nIn this paper, we focus on two test sets:\nGrammars for each test set\nTuned Grammars were used by Joshua to translate all test sets.<et>Tunedgrammars are used by the Joshua decoder to translate the test setsMapping of the translation grammar\nLinguistic and linguistic features\nLanguage pairs are grouped into a single test set.",
            "result_pred": "Managing Experiment Workflows\nManaging experiment workflows is tricky!\nFortunately, there's human judgments to rely on.\nNeed to do force-level optimization.Manual Configuration\nThe following scripts are used for configuration:\ndistmake: distributed make using a distributed scheduler\ntuned-out-of-domain (dist)\nsun-studied-make: pipelined-make using a pre-trained make kernelExperimental Results\nBaseline: run one run for each language pair\nSix language pairs in the translation shared task: English-French, English-German, French-English, German-English\nEnglish-Spanish, Italian-Italian, Spanish-English and Italian-German",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "443",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\n.............\n refer to previous work\nTask: Patent Machine Translation Task\nPatent Translation Task\nPatented Translation Task: Patent Translation TaskPentagraphs and documents\nPapers & documentsPatents & documents<et>Patent documents and documents\nTitle of a document\nTitle and documentPapers and documents:\nWhat is a patent?What are patents?\nHow do patents differ from documents?\nHow does a patent differ from a document?",
            "result_pred": "Human evaluation\nHuman evaluation of Tapta driven translation\nCoached by 2 professional translator-revisers\n516 total translations produced by the testers\nhalf of the translations produced were deemed publishable after revision\nThe other half were not publishableHuman Evaluation\nBLEU score increase of 0.9 percentage points\nHuman Evaluation\nImprovement of BLEU is not statistically significant\nA human judgment on the accuracy of proposals on a human-driven segmented text is the only good metric.\n\"QC-improved\" and \"Domain-aware\" models are rather disappointing in terms of translating quality.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "449",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "Word-based Alignment\nWord alignment\nAlignment with SL words\nThe target word w ij is not aligned to any source word in s i , and that in these words, nothing can be said about it.\nIt may be aligned with source word v ik which is in the part of s i that does not match s .\nWe have chosen the likelihood that word wij will be kept unedited to depend on how many SL words aligned with it, and the SL segment to be translated, SL words are matched with it.\nWe chose the likelihood to keep unedited SL words uneditedWe have used the optimal edit path, obtained from the optimal translation path, based on the optimal word-based distance.Word-aligned Alignment\nTarget word w Ij may have to be changed because it is aligned with SL word v i , but it is not matched with SL segment\nS i and s i are not aligned with each other, and we have to change the SL word to be matched with s .\nSi and si are aligned with s i .Alignment of SL words with target word W ij\nW ij and S i are aligned, but they are not matched\nMatching SL words:\nSL words are aligned and matched with the target word, and they are un-edited\nUnedited words are kept un edited\nNon-aligned SL words can be unedited, but we have not changed the SL words to be aligned\nNo word-aligned words are unedited in this study\nAll SL words must be aligned and unedited.",
            "result_pred": "Experimental settings\nWe first obtained the word alignments by means of the intersection method.\nFor each SL segment, we obtained the TUs with a fuzzy-match score above threshold \u0398, and tagged the words in their target segments as \"keep\" or \"change\".\nAccuracy and coverage obtained with each set of alignments\nThe accuracy is the percentage of times the recommendation of our system is correct, and the coverage is slightly better than the coverage obtained for the alignment obtained by the alignment method with the majority criterion.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "460",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nHuman Error Classification\nHuman error classification\nThe human error classification is definitely not unambigous - often not determine the particular error category.Human error Classification\nIn this work, two types of human error analysis using reference translations are carried out:\nHeterogeneity of error classes\nSensitivity of error class\nLinguistic and syntactic differences\nError classification and classification\nThe automatic method of error analysis and classification proposed in (Vilar et al., 2006) are defined: \u2022 inflectional errors occur if the base form of the generated word is correct but the full form is not. \u2022 synonyms are not in the reference. \u2022 errors occur when the source sentence is incorrect but the source form is correct. \u2022 error classes are not assigned in the hypothesis\nNo reference translation at all, but compare the translation output with the source text.<et>No reference translations at all\nOnly the reference translation is available, but the reference with the lowest WER score is choosen for all metrics.\nNo references are available\nNot all errors occur in the target hypothesisHeterogeneous error classes\nNot only the reference translations, but also the source sentences are incorrect\nNon-reference translations are correct, but they do not appear in the test hypothesis.Not every error class is assigned in a test hypothesis",
            "result_pred": "Experimental set-up\nSix English translation outputs obtained by state-ofthe-art statistical phrase-based systems in the framework of the GALE 1 project and the fourth Workshop on Statistical Machine Translation 2\nTwo GALE outputs are translations from Arabic into English, and the third is a result of Chinese-to-English translation\nThree WMT outputs are translation from the same German text into English\nHuman error analysis for all texts and all error classes\nThe results of both human and automatic error analysis are similar\nFour out of five error classes are correlated with human judgments across different error classes (rightmost column)Automatic results\nHuman and automatic results are similar for each error class\nFor the WMT output, the correlation coefficient is slightly lower than for the human output\nThis corresponds to the fact that the automatic method can successfully substitute human analysis in order to answer the questions that the overall ranking evaluation metrics cannot answer.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "466",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": "WORLDWARE CONFERENCEWORLDWare CONFERENCORENCE: WORLDWARECONFERENCE\nMore capacity is upping the ante. \"Contrary to all expectations, using MT in Bentley has improved the translation quality in the pilot projects\" French OLH reviewer: \"I give a 9\u2026I find this translation very good\u2026I found it better than the translations I used to see before\" German courseware reviewer: It was the first time I saw this translation. \"I find it very good. I found it much better than what I saw before\" French courseware review: \"This translation is very good.\" \"I found this translation to be very good\" French OH reviewer\nFrench OLH review: I give this translation a 9. \"This is a very good translation.\" \"This translates very good\". \"I think this translation is a good translation. I find it better.\" French OHL reviewer: This translation is much better. \"The translation quality is good.\"\"This translation has a 9\u2026\"I give it a 9...I find that it is good. \"French courseware reviewers: \"It was the 1st time that I saw it.\" \"It is a lot better than before\". \"This translator is good\" \"I don't find it worse than before.\"\"I found that it was the 2nd time that we saw it before.\" French course ware reviewer: I find this to be good.\nGerman courseware reviews: \"this translation is good\u2026\" \"I have found it to be better\" \"This transfer is good\", \"I can't find anything worse than this translation\" French language reviewer:\"This is good,\" \"I cannot find something worse than that this translation\", \"this is good\".\"I find these translations to be bad\" French and German language reviewers\n\"I give an 8.5\u2026I give this to this translation.\" French language reviewers: I have a 9\"French language reviewers : \"I do not find it bad\" German language reviewer : \"This translate is good, I found this translator to be worse\" French literature reviewer: 1.5 \"French language reviewer\": \"I gave this translation an 8\" \"German language reviewer:\" 1.4 \"German Language reviewer\": 1.6 \"German\"\nEnglish language reviewer\nSpanish language reviewer reviewer: 2.0 \"English language reviewers\": 2.1 \"Spanish language reviewers\" Spanish language reviewers reviewer: 3.0\"",
            "result_pred": "Exploding content is creating new needs\nExploding Content (Exploding Data) is generating new needs\nNew York Times contains more information than an 18 th century person encountered in a lifetime\nMore unique information will be generated this year than in the previous 5000 years\nWeb site is at the forefront of this explosion\nGoogle News is the largest source of new information on the web\nThe New York Times has the most-read articles on the Web\nStatistical significance of this increase\n\"Web site has the largest amount of new content in the last decade.\"Explosion of Content\nExpansion of Content (Expansion) is the most important change\n10 fold more web site users sent in one day than the population of the world Symantec created more content last year than the previous decade",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        },
        {
            "id": "469",
            "introduction_pred": "Introduction\nHierarchical reinforcement learning (HRL) is a promising approach for solving temporally extended tasks by learning a hierarchy of policies\nHRL models can be adapted to the needs of the task at hand\nMOTIVATION IN TRANSLATION",
            "method_pred": ".\nWe assume that in the case of low e-resourced languages, this parallel corpus, even small, may not be available.We try to propose a fully unsupervised method, here, where the starting point is just a simple noisy comparable corpus, without using additional parallel data.\nWe propose a method for extracting parallel sub-sentential fragments from a very non-parallel corpus.<et>We propose an iterative process to extract parallel data from comparable corpora\nThe target corpus contains data which is not parallel, but is still closely related to conveying the same information, such as words, phrases, clauses, sentences, and discourses\nOur approach\nIn this paper, we focus on parallel data in comparable corporas\nA parallel corpus contains similar corpus, but not parallel\nThis corpus contains parallel data which are not parallel but are closely related\nComparative corpus contains different corpus, and not parallel data\nUnsupervised methods\nSemi-supervised v/s unsuper supervised methodsSemi -supervised V/s Unsupervised Methods\nSynchronizing parallel data with the target corpusSynchronized parallel data between the source corpus and target corpus\nSynchronous parallel data across the source side of the corpus\nSimilar corpus with similar corpus",
            "result_pred": "Evaluation of translation systems\nTranslation system evaluation - e.g. Europarl corpus\n400 French-English parallel sentence pairs were extracted using only one English reference.\nThe quality of the translation system was increased quickly during some first iterations, but decreased after that\nA lot of new parallel sentences were extracted and included to the translation model\nMore wrong sentence pairs got added to the system so the quality of translation system got worse\nImprovement was limited due to the limited number of parallel data.",
            "conclusion_pred": "Conclusion\nWe propose a new approach to improve the performance of neural networks in neural networks.\nFuture work\nWe proposed a new neural network architecture for neural networks that improves the performance on neural networks, and improves the accuracy of the neural network."
        }
    ]
}